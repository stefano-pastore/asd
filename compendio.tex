\documentclass[11pt,a4paper,oneside]{article}
\usepackage{fullpage}
\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{array}
\usepackage{listings}
\usepackage{centernot}
\usepackage{mathtools}
\usepackage{bm}
\usepackage[table]{xcolor}
\usepackage{breqn}
\usepackage{color}
\usepackage{hyperref}
\usepackage{pgfplots}
\usepackage{tcolorbox}
\usepackage{subcaption}
\usepackage{multicol}
\usepackage{enumitem}
\usepackage[makeroom]{cancel}
\pgfplotsset{compat=1.12}
\usetikzlibrary{positioning}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{shapes.multipart, calc}
\usepackage[font={footnotesize,it},width=.5\textwidth]{caption}

\hypersetup{%
	colorlinks=true,
	linkcolor=cyan,
	urlcolor=cyan
}

% CUSTOMIZATIONS
\definecolor{t1}{HTML}{C32024}
\definecolor{t2}{HTML}{141543}
\definecolor{t3}{HTML}{1052A6}
\definecolor{t4}{HTML}{06B0E6}

\definecolor{g1}{HTML}{CFCFCF}
\definecolor{g2}{HTML}{ADADAD}

\renewcommand\arraystretch{1.3} \setlength\minrowclearance{1.2pt}

\lstset{ %
	backgroundcolor=\color{white},
	basicstyle=\footnotesize\ttfamily,
	breakatwhitespace=false,
	breaklines=true,
	captionpos=b,
	commentstyle=\color{mygreen},
	deletekeywords={...},
	escapeinside={\%*}{*)},
	extendedchars=true,
	keepspaces=true,
	keywordstyle=\color{blue},
	keywords={AND,OR,NOT,FOR,IF,RETURN,TO,THEN,ELSE,WHILE,DO},
	numbers=left,
	numbersep=5pt,
	numberstyle=\tiny\color{g1},
	rulecolor=\color{black},
	showspaces=false,
	showstringspaces=false,
	showtabs=false,
	stepnumber=1,
	stringstyle=\color{mymauve},
	tabsize=2,
	title=\lstname
}

%opening
\title{Raccolta di appunti per il corso di\\\Huge{Algoritmi e Strutture Dati}}
\author{Stefano Pastore}

\begin{document}
 \rowcolors{2}{gray!25}{white}

\maketitle
\pagebreak
\tableofcontents
\pagebreak

\section*{Disclaimer e licenza}
\paragraph*{} Questi appunti sono rilasciati sotto licenza \href{https://creativecommons.org/licenses/by-nc-sa/4.0/}{Creative Commons 4.0 by-nc-sa}.
\paragraph*{} Si fa presente che questo documento viene stilato senza pretese di assoluta correttezza né di esaustività. Qualora si siano rinvenuti degli errori, è possibile segnalarli all'indirizzo\linebreak \href{mailto:ste.pastore@studenti.unina.it}{ste.pastore@studenti.unina.it}. È consultabile il repository di tutto il materiale prodotto a disposizione di chiunque su \href{https://github.com/stefano-pastore/asd}{Github}.
\pagebreak
\section{Definizioni basilari}
\subsection{Algoritmi e complessità}
\paragraph*{} Un algoritmo è una procedura ben definita per risolvere un problema, vale a dire, una sequenza finita di passi che, se svolti da un esecutore, conducono alla soluzione del problema.
\paragraph*{} Nella stesura di un algoritmo risulta sempre di cruciale importanza ottenere una misura delle risorse computazionali che esso impiega per risolvere un problema. Alcuni esempi sono il tempo di esecuzione, la memoria impiegata o la banda di comunicazione.
\paragraph*{} Nello studio ci concentreremo in questa sede sul \textbf{tempo di esecuzione} di un programma, che generalmente può dipendere da vari fattori quali l'hardware su cui viene eseguito, il compilatore o l'interprete che viene utilizzato, carico di lavoro sull'unità di calcolo. Tuttavia anziché analizzare la complessità di tempo di un algoritmo su macchine specifiche e quindi con caratteristiche hardware e software potenzialmente drammaticamente diverse, punteremo allo studio del \textit{tempo intrinseco} necessario all'algoritmo per giungere alla soluzione in modo più astratto, impiegando il modello computazionale RAM, che si basa sulla macchina di Turing.
\paragraph*{}Proprio al fine di effettuare questo studio più astratto, possiamo pensare di associare ad ogni passo dell'algoritmo il numero di operazioni necessarie per eseguirlo. La somma di tutte le operazioni elementari effettuate su ogni passo danno come risultato una formula che nei fatti è una vera e propria \textbf{funzione matematica}.
\paragraph*{}Sia $T(n)$ una funzione che esprime il tempo di esecuzione dell'algoritmo associato $Algo(n)$, dove $n$ è l'input di un certo tipo e dotato di una certa dimensione.
\subsubsection{Confrontare funzioni di tempo}
\paragraph*{}Supponiamo di avere quattro algoritmi diversi tra loro ma che risolvono tutti un certo problema $P$. Come possiamo stabilire qual è l'algoritmo migliore? Una volta contato il numero di operazioni elementari di ogni algoritmo, supponiamo di avere seguenti dati come mostrati in tabella \ref{tab:algos}:

\begin{table}[h]
	\centering
	\begin{tabular}{|c|l|}
		\hline
		\textbf{Algoritmo}&\textbf{Tempo di esecuzione}\\\hline 
		Algoritmo A &  $T_A(n) = 9n^2+9n+4$ \\ 
		Algoritmo B &  $T_B(n) = 2n^2+6n+4$\\ 
		Algoritmo C &  $T_C(n) = 6n+4$\\ 
		Algoritmo D &  $T_D(n) = 5$ \\ \hline
	\end{tabular}
	\caption{Confronto tra funzioni di tempo di esempio associate a quattro algoritmi che risolvono un medesimo problema $P$.}
	\label{tab:algos}
\end{table}

Naturalmente l'algoritmo migliore sarà quello che per $n \to \infty$ detiene la minore velocità di crescita. Nell'esempio sopra citato l'algoritmo migliore è il $D$ perché per qualsiasi dimensione in input, il tempo di esecuzione rimane costante e dunque non cresce.

\paragraph*{} Al fine di riuscire a confrontare le funzioni di tempo con strumenti ben noti, si introducono le seguenti definizioni.
\paragraph{\fcolorbox{white}{black}{\color{white}Limite asintotico superiore}} Siano $f(n)$ e $g(n)$ due funzioni. Si dice che $g(n)$ è \textbf{limite asintotico superiore} per $f(n)$ e si scrive $\bm{f(n) = O(g(n))}$ se è possibile riuscire a trovare una costante $c$ positiva tale per cui, per ogni valore $n$ maggiore di un certo $n_0$ positivo fissato, risulta che $f(n) \leq  c\cdot g(n)$ o formalmente: $$\exists c>0, \exists n_0 > 0 : \forall n \geq n_0,\,f(n) \leq c\cdot g(n)$$
\subparagraph*{Un esempio} Supponiamo di avere due funzioni. Sia $f(n) = n$ e $g(n) = e^n-\frac{5}{2}n$ e per avere un'idea immediata, visualizziamone l'andamento.

% adding_dotted
\begin{figure}[hb]
\centering
\begin{tikzpicture} [label/.style={%
	postaction={ decorate,transform shape,
	decoration={ markings, mark=at position .2 with \node #1;}}}]
\begin{axis}[domain=0:5, samples=50,grid=major, legend style={legend cell align=left, font=\tiny},
restrict y to domain=0:5,xlabel=$\text{Dimensione dell'input}$,ylabel=$\text{Tempo di esecuzione}$, legend pos=north west]
\addplot [thick, color=red]    {x};
\addplot [thick, color=green]  {e^x-5/2*x};

\legend{$n$, $e^n-\frac{5}{2}n$}
% \draw [thick,dashed] (2,\pgfkeysvalueof{/pgfplots/ymin}) -- (2,\pgfkeysvalueof{/pgfplots/ymax});
\draw [thick,dashed,label={[below]{$n_0$}}] (2,\pgfkeysvalueof{/pgfplots/ymin}) -- (2,\pgfkeysvalueof{/pgfplots/ymax});
\end{axis}
\end{tikzpicture}
\caption{In figura $f(n) = n$ e $g(n) = e^n-\frac{5}{2}n$.}
\label{fig:asymsup}
\end{figure}

\paragraph*{}Guardando la figura \ref{fig:asymsup} è facile convincersi che $g(n)$ scelta nell'esempio sia un limite superiore asintotico. Infatti opportunamente scelti $c = 1$ e $n_0 = 2$, si può verificare che $g(n)$ rimane sempre al di sopra di $f(n)$ per qualsiasi valore a partire da $n_0$ fissato in poi.\\

\begin{tcolorbox}[title=Nota bene]
	Nel caso di quest'esempio avrei potuto scegliere un $n_0$ avente un qualsiasi valore superiore a $2$ e la proposizione, che definisce il limite superiore asintotico, sarebbe comunque risultata vera. Diversamente non avrei potuto scegliere $n_0 = \frac{1}{16}$ poiché per $n = n_0 = 1$ la funzione $g(n)$ si trova al di sotto di $f(n)$, il che violerebbe $\forall n \geq n_0,\,f(n) \leq c\cdot g(n)$.
\end{tcolorbox}
\pagebreak
\paragraph{\fcolorbox{white}{black}{\color{white}Limite asintotico inferiore}} Siano $f(n)$ e $g(n)$ due funzioni. Si dice che $g(n)$ è \textbf{limite asintotico inferiore} per $f(n)$ e si scrive $\bm{f(n) = \Omega(g(n))}$ se è possibile riuscire a trovare una costante $c$ positiva tale per cui, per ogni valore $n$ maggiore di un certo $n_0$ positivo fissato, risulta che $f(n) \geq  c\cdot g(n)$ o formalmente: $$\exists c>0, \exists n_0 > 0 : \forall n \geq n_0,\,f(n) \geq c\cdot g(n)$$

\subparagraph*{Un esempio} Supponiamo di avere due funzioni. Sia $f(n) = n^3-\frac{1}{3}n$ e $g(n) = n^2$. Per avere subito un'idea di come queste due funzioni si comportano, visualizziamone l'andamento.

\begin{figure}[hb]
	\centering
	\begin{tikzpicture} [label/.style={%
		postaction={ decorate,transform shape,
		decoration={ markings, mark=at position .1 with \node #1;}}}]
	\begin{axis}[domain=0:25, samples=150,grid=major, legend style={legend cell align=left, font=\tiny},
	restrict y to domain=0:25,xlabel=$\text{Dimensione dell'input}$,ylabel=$\text{Tempo di esecuzione}$, legend pos=south east]
	\addplot [thick,color=red]    {x^2};
	\addplot [thick,color=green]  {x^3-1/3*x};
	
	\legend{$n^2$, $n^3-\frac{1}{3}n$}
	% \draw [thick,dashed] (2,\pgfkeysvalueof{/pgfplots/ymin}) -- (2,\pgfkeysvalueof{/pgfplots/ymax});
	\draw [thick,dashed,label={[below]{$n_0$}}] (2,\pgfkeysvalueof{/pgfplots/ymin}) -- (2,\pgfkeysvalueof{/pgfplots/ymax});
	\end{axis}
	\end{tikzpicture}
	\caption{In figura $f(n) = n^3-\frac{1}{3}n$ e $g(n) = n^2$.}
	\label{fig:asyminf}
\end{figure}
\paragraph*{} Ancora una volta, dando un'occhiata al grafico delle due funzioni, è lampante accorgersi del fatto che $g(n)$ è limite inferiore asintotico poiché scelte $c = 1$ ed $n_0 = 2$, dal grafico notiamo che la funzione rimane sempre al di sotto di $f(n)$.
\pagebreak
\paragraph{\fcolorbox{white}{black}{\color{white}Limite asintotico stretto}}\label{par:asymstr} Siano $f(n)$ e $g(n)$ due funzioni. Si dice che $g(n)$ è \textbf{limite asintotico stretto} per $f(n)$ e si scrive $\bm{f(n) = \Theta(g(n))}$ se è possibile riuscire a trovare due costanti $c_1$ e $c_2$ positive tali per cui, per ogni valore $n$ maggiore di un certo $n_0$ positivo fissato, risulta che $c_1\cdot g(n) \leq f(n) \leq  c_2\cdot g(n)$ o formalmente: $$\exists c_1>0, \exists c_2 > 0, \exists n_0 > 0 : \forall n \geq n_0,\,c_1\cdot g(n) \leq f(n) \leq c_2\cdot g(n)$$

\subparagraph*{Un esempio} Supponiamo di avere due funzioni. Sia $f(n) = 2n^2-\frac{1}{3}n$ e $g(n) = n^2+2n$. Per avere subito un'idea di come queste due funzioni si comportano, visualizziamone l'andamento.
\begin{figure}[hb]
	\centering
	\begin{tikzpicture} [label/.style={%
		postaction={ decorate,transform shape,
		decoration={ markings, mark=at position .1 with \node #1;}}}]
	\begin{axis}[domain=0:50, samples=500,grid=major, legend style={legend cell align=left, font=\tiny},
	restrict y to domain=0:150,xlabel=$\text{Dimensione dell'input}$,ylabel=$\text{Tempo di esecuzione}$, legend pos=south east]
	\addplot [thick,color=red]    {x^2+2*x};
	\addplot [thick,color=green]  {2*x^2-1/3*x};
	\addplot [thick,color=red]    {4*(x^2+2*x)};
	
	\legend{$n^2+2n$, $2n^2-\frac{1}{3}n$, $4n^2-8n$}
	\draw [thick,dashed,label={[below]{$n_0$}}] (3,\pgfkeysvalueof{/pgfplots/ymin}) -- (3,\pgfkeysvalueof{/pgfplots/ymax});
	\end{axis}
	\end{tikzpicture}
	\caption{In figura $f(n) = 2n^2-\frac{1}{3}n$ e $g(n) = n^2+2n$.}
	\label{fig:asymstr}
\end{figure}
\paragraph*{}Possiamo concludere che in questo caso $f(n) = \Theta(g(n))$ dal momento che per $c_1 = 1$, $c_2 = 4$ e per qualsivoglia $n$ maggiore di $n_0 = 3$, la funzione $f(n)$ rimane intrappolata tra le altre due, cioè, $1 \cdot (n^2+2n) \leq 2n^2-\frac{1}{3}n \leq 4 \cdot (n^2+2n)$.
\pagebreak
\subsubsection{Correlazione tra limite di funzioni e limiti asintotici}
\paragraph*{}Sino a questo punto si son analizzati l'andamento e la crescita in maniera naïf, basando il ragionamento sui grafici di funzioni. Sarebbe opportuno dare una rappresentazione non troppo formale, ma sufficientemente convincente che consenta di poter effettuare uno studio di carattere più analitico. 
\paragraph*{} Siano $f(n)$ e $g(n)$ due qualsivoglia funzioni. In particolare dimostriamo informalmente che 
\begin{equation}
\lim_{n\to \infty} \frac{f(n)}{g(n)} = k > 0 \Leftrightarrow f(n) = \Theta(g(n))
\label{eq:equiv}
\end{equation}
è vera.
\paragraph*{\fcolorbox{white}{black}{\color{white}Dimostrazione}} Per la definizione di $\Theta(.)$ che conosciamo, data nel paragrafo \ref{par:asymstr}, sappiamo che $\exists c_1>0, \exists c_2 > 0, \exists n_0 > 0 : \forall n \geq n_0,\,c_1\cdot g(n) \leq f(n) \leq c_2\cdot g(n)$. Tralasciando per il momento i quantificatori esistenziali e concentrandoci solamente sulla parte della definizione che coinvolge le disuguaglianze abbiamo che: 
\begin{equation}
c_1 \cdot g(n) \leq f(n) \leq c_2\cdot g(n) \Rightarrow c_1 \leq \frac{f(n)}{g(n)} \leq c_2 \label{eq:eq1}
\end{equation} dopo aver supposto che prendendo un punto $n$ all'interno dell'intervallo di interesse, $g(n)$ non sia nulla e venga preservata la relazione d'ordine. La disequazione alla quale siamo giunti ci indica che il rapporto tra le due funzioni $f$ e $g$ è limitato tra due costanti. Un esempio è mostrato in figura \ref{fig:limits}.

\begin{figure}[hb]
	\centering
	\begin{tikzpicture} [label/.style={%
		postaction={ decorate,transform shape,
		decoration={ markings, mark=at position .5 with \node #1;}}}]
	\begin{axis}[ticks=none,domain=0:500, samples=1250,grid=major, legend style={legend cell align=left, font=\tiny},
	restrict y to domain=0:100,xlabel=$\text{Dimensione dell'input}$,ylabel=$\text{Tempo di esecuzione}$, legend pos=south east]
	\addplot [thick,color=red]    {(3*x^2-x)/(x^2+x)};
	
	\legend{$\frac{f(n)}{g(n)}$}
	\draw [thick,dashed,label={[below]{$n_0$}}] (30,\pgfkeysvalueof{/pgfplots/ymin}) -- (30,\pgfkeysvalueof{/pgfplots/ymax});
	\draw [thick,dotted,label={[above]{$c_1$}}] (\pgfkeysvalueof{/pgfplots/xmin},3) -- (\pgfkeysvalueof{/pgfplots/xmax},3);
	\draw [thick,dotted,label={[below]{$c_2$}}] (\pgfkeysvalueof{/pgfplots/xmin},2.7) -- (\pgfkeysvalueof{/pgfplots/xmax},2.7);
	\end{axis}
	\end{tikzpicture}
	\caption{Il rapporto tra le due funzioni $f$ e $g$ scelte è chiaramente limitato tra le due costanti $c_1$ e $c_2$ a partire da un fissato $n_0$.}
	\label{fig:limits}
\end{figure}
\paragraph*{} Possiamo osservare che da $n_0$ in avanti la funzione deve rimanere intrappolata tra i valori di queste due costanti e non potrebbe essere altrimenti. Se immaginassimo per assurdo che per $n \to \infty$ il rapporto tra $f$ e $g$ tendesse ad infinito, allora il limite del rapporto andrebbe al di sopra del valore di $c_2$ tracciato, cosa che è in contraddizione con quanto ricavato nella disequazione \ref{eq:eq1}. In maniera analoga, il limite del rapporto tanto meno può tendere a $0$ per $n \to \infty$, dal momento che $c_1$ e $c_2$ le abbiamo supposte come strettamente positive.
\paragraph*{}Nel mettere in correlazione le due definizioni come mostrato nella proposizione \ref{eq:equiv} dobbiamo porci il problema di come trovare le costanti $n_0$, $c_1$, $c_2$ a partire dal valore $k$ del limite e viceversa. Allora supponiamo che sia vera $\lim_{n \to \infty} \frac{f(n)}{g(n)} = k > 0$ e diamone un'interpretazione geometrica. Rivisitando l'esempio in figura \ref{fig:limits} abbiamo:

\begin{figure}[hb]
	\centering
	\begin{subfigure}[b]{0.4\textwidth}
	\centering
	\resizebox{\linewidth}{!}{
	\begin{tikzpicture} [label/.style={%
		postaction={ decorate,transform shape,
			decoration={ markings, mark=at position .5 with \node #1;}}}]
	\begin{axis}[ticks=none,domain=0:250, samples=500,grid=major, legend style={legend cell align=left, font=\tiny},
	restrict y to domain=0:100,xlabel=$\text{Dimensione dell'input}$,ylabel=$\text{Tempo di esecuzione}$, legend pos=south east]
	\addplot [thick,color=red]    {(3*x^2-x)/(x^2+x)};
	
	\legend{$\frac{f(n)}{g(n)}$}
	\draw [thick,dashed,label={[below]{$n_0$}}] (30,\pgfkeysvalueof{/pgfplots/ymin}) -- (30,\pgfkeysvalueof{/pgfplots/ymax});
	\draw [thick,dotted,label={[below]{$k$}}] (\pgfkeysvalueof{/pgfplots/xmin},3) -- (\pgfkeysvalueof{/pgfplots/xmax},3);
	\end{axis}
	\end{tikzpicture}
	}
	\caption{Grafico che mostra funzione non decrescente che tende a $k$ dal basso.}
	\label{fig:tokfrombelow}
	\end{subfigure}
	\quad
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\resizebox{\linewidth}{!}{
			\begin{tikzpicture} [label/.style={%
				postaction={ decorate,transform shape,
					decoration={ markings, mark=at position .5 with \node #1;}}}]
			\begin{axis}[ticks=none,domain=0:250, samples=500,grid=major, legend style={legend cell align=left, font=\tiny},
			restrict y to domain=0:100,xlabel=$\text{Dimensione dell'input}$,ylabel=$\text{Tempo di esecuzione}$, legend pos=south east]
			\addplot [thick,color=red]    {(3*x^2)/(x^2-x)};
			
			\legend{$\frac{f(n)}{g(n)}$}
			\draw [thick,dashed,label={[below]{$n_0$}}] (30,\pgfkeysvalueof{/pgfplots/ymin}) -- (30,\pgfkeysvalueof{/pgfplots/ymax});
			\draw [thick,dotted,label={[above]{$k$}}] (\pgfkeysvalueof{/pgfplots/xmin},3) -- (\pgfkeysvalueof{/pgfplots/xmax},3);
			\end{axis}
			\end{tikzpicture}
		}
		\caption{Grafico che mostra funzione non crescente che tende a $k$ dall'alto.}
		\label{fig:limits4}
	\end{subfigure}
	\caption{Il valore del limite $k$ denota l'equazione della retta che è un asintoto per la funzione costituita dal rapporto tra $f$ e $g$.}
	\label{fig:tokfromabove}
\end{figure}
\paragraph*{}Come si vede chiaramente dai grafici, il rapporto $\dfrac{f(n)}{g(n)}$ può tendere a $k$ dal basso oppure dall'alto. Quindi esaminiamo i due casi schematicamente:
\begin{description}
	\item[il rapporto tende dal basso] posso prendere una qualsiasi costante $c_2 \geq k$, dal momento che il limite del rapporto non supera mai $k$ stesso e $c_1 = \frac{f(n_0)}{g(n_0)}$ perché per $n_0$ si otterrà il più piccolo valore di $\frac{f(n)}{g(n)}$, essendo la funzione non decrescente.
	\item[il rapporto tende dall'alto] posso prendere un qualsiasi $c_1 \leq k$ poiché il rapporto non assume mai valori inferiori a quello dell'asintoto orizzontale $k$ e $c_2 = \frac{f(n_0)}{g(n_0)}$ perché per $n_0$ si otterrà il più grande valore di $\frac{f(n)}{g(n)}$, essendo la funzione non crescente.
\end{description}
\subsubsection{Proprietà generali della notazione asintotica}
\paragraph*{} Altre proprietà addizionali da conoscere per la risoluzione degli esercizi. Siano $f$ e $g$ due funzioni.
\begin{multicols}{3}
	\begin{enumerate}[series=qa,label=(\textit{\alph*})]
		\item $f(n) = \Theta(f(n))$
		\item $f(n) = O(f(n))$
		\item $f(n) = \Omega(f(n))$
	\end{enumerate}
\end{multicols}
\begin{multicols}{2}
	\begin{enumerate}[resume*=qa,label=(\textit{\alph*})]
		\item $f(n) = \Theta(g(n)) \Leftrightarrow g(n) = \Theta(f(n))$
		\item $f(n) = O(g(n)) \Leftrightarrow g(n) = \Omega(f(n))$ \label{itm:not1}
	\end{enumerate}
\end{multicols}
	\begin{enumerate}[resume*=qa,label=(\textit{\alph*})]
		\item $f(n) = \Theta(g(n)) \wedge g(n) = \Theta(h(n)) \Rightarrow f(n) = \Theta(h(n))$
		\item $f(n) = O(g(n)) \wedge g(n) = O(h(n)) \Rightarrow f(n) = O(h(n))$ \label{itm:not2}
		\item $f(n) = \Omega(g(n)) \wedge g(n) = \Omega(h(n)) \Rightarrow f(n) = \Omega(h(n))$
	\end{enumerate}

\paragraph*{} Dimostriamo le proprietà \ref{itm:not1} e \ref{itm:not2}.
\paragraph*{} Siano $f$ e $g$ due funzioni, dimostriamo che $f(n) = O(g(n)) \Leftrightarrow g(n) = \Omega(f(n))$.
\paragraph*{\fcolorbox{white}{black}{\color{white}Dimostrazione $\Rightarrow$}} Facendo riferimento alle rispettive definizioni di $\Omega(.)$ e $O(.)$ vogliamo provare che $$\exists n_0 > 0, \exists c_0 >0 : \forall n \geq n_0,\,f(n) \leq c_0\cdot g(n) \Rightarrow \exists n_1 > 0, \exists c_1 >0 : \forall n \geq n_1,\,c_1\cdot f(n) \leq g(n)$$
\paragraph*{}Fissiamo $c_0 > 0$ e $n_0 > 0$ allora $\forall n \geq n_0,\,f(n)\leq c_0\cdot g(n)$ è vero per quanto assunto. Dividiamo ambo i membri della diseguaglianza per $c_0$, dal momento che è una costante non nulla e otteniamo: $$\frac{1}{c_0}f(n) \leq g(n)$$ notiamo che $c_0 > 0 \Rightarrow \frac{1}{c_0} > 0$ e quindi ponendo $n_0 = n_1$ e $\frac{1}{c_0} = c_1$, la proposizione risulta verificata.
\paragraph*{\fcolorbox{white}{black}{\color{white}Dimostrazione $\Leftarrow$}} Invertendo le definizioni, analogamente si dimostra anche il senso contrario della proposizione.
\paragraph*{} Siano $f$, $g$ ed $h$ tre funzioni, dimostriamo che vale la proprietà transitiva sulla definizione di $O(.)$ cioè $f(n) = O(g(n)) \wedge g(n) = O(h(n)) \Rightarrow f(n) = \Omega(h(n))$.
\paragraph*{\fcolorbox{white}{black}{\color{white}Dimostrazione}} Ancora una volta trasformiamo la proposizione, sostituendo alle notazioni le loro rispettive definizioni si deve provare che:
\[
\begin{array}{l}
\exists n_0 > 0,\, \exists c_0 > 0: \forall n \geq n_0,\,f(n) \leq c_0\cdot g(n) \\
\exists n_1 > 0,\, \exists c_1 > 0: \forall n \geq n_1,\,g(n) \leq c_1\cdot h(n) 
\end{array} \Rightarrow \exists n_2 > 0, \exists c_2 > 0 : \forall n \geq n_2,\,f(n) \leq c_2\cdot h(n)
\]
\paragraph*{}Per fare in modo che le due proposizioni dell'ipotesi siano contemporaneamente vere scegliamo $n_2 = \max\{n_0, n_1\}$ e riscriviamo quanto sopra:
\[
\begin{array}{l}
\exists n_0 > 0,\, \exists c_0 > 0: \forall n \geq \bm{n_2},\,f(n) \leq c_0\cdot g(n) \\
\exists n_1 > 0,\, \exists c_1 > 0: \forall n \geq \bm{n_2},\,g(n) \leq c_1\cdot h(n) 
\end{array} \Rightarrow \exists n_2 > 0, \exists c_2 > 0 : \forall n \geq n_2,\,f(n) \leq c_2\cdot h(n)
\]
a questo punto dalla definizione abbiamo che $f(n) \leq c_0\cdot g(n)$ e $g(n) \leq c_1\cdot h(n)$ e moltiplicando ambo i membri della seconda diseguaglianza per $c_0$, che abbiamo definito strettamente positiva, otteniamo: $$c_0\cdot g(n) \leq c_0 \cdot c_1 \cdot h(n)$$ ma $f(n) \leq c_0\cdot g(n)$ e quindi ponendo $c_2 = c_0 \cdot c_1$ si giunge a $$f(n) \leq c_0\cdot g(n)\leq c_2 \cdot h(n) \Rightarrow f(n) \leq c_2\cdot h(n)$$ e l'implicazione è dimostrata.
\pagebreak
\subsubsection{Esercizi svolti}
\paragraph*{} Segue in questa sezione lo svolgimento completo di due esercizi eseguiti durante la lezione.\\

\begin{tcolorbox}[title=Ricorda che...]
	\label{tbox:solving}
	La risoluzione di questo tipo di esercizi passa essenzialmente per tre punti:
	\begin{enumerate}
		\item verificare che il limite \textbf{tenda} ad una costante $k > 0$
		\item individuare l'infinito intervallo aperto posto \textbf{più a destra} in cui il rapporto delle due funzioni è monotono
		\item analizzare la \textbf{crescenza} o \textbf{decrescenza} del rapporto.
	\end{enumerate}
\end{tcolorbox}


\paragraph*{Esercizio} Dimostrare che $n^2+2n+1 = \Theta(n^2)$.
\paragraph*{Svolgimento} Innanzitutto verifichiamo che il rapporto del limite tenda ad una costante strettamente positiva: $$\lim_{n\to \infty} \dfrac{n^2+2n+1}{n^2} = \lim_{n\to \infty} \left( \cancelto{1}{\dfrac{n^2}{n^2}} + \cancelto{0}{\dfrac{2n}{n^2}} + \cancelto{0}{\dfrac{1}{n^2}}\right) = 1$$\\\\Essendo il rapporto composto unicamente da membri positivi, l'intervallo aperto più a destra è $\mathbb{R}^{+}\setminus{\{0\}}$.\\\\Infine per valutarne la crescenza o la decrescenza, possiamo calcolare la derivata del rapporto:
$$\dfrac{\partial \left(1+\dfrac{2}{n}+\dfrac{1}{n^2} \right)}{\partial n} = 0 - \dfrac{2}{n^2} - \dfrac{2}{n^3}$$
a questo punto risulta lampante osservare che per $n > 0$ le due frazioni che compaiono come risultato della derivata sono negative, cioè: $-\dfrac{2}{n^2} -\dfrac{2}{n^3}<0,\,\forall n > 0$ e quindi il rapporto delle due funzioni ha un andamento decrescente.\\\\Per quanto detto nelle conclusioni del paragrafo precedente possiamo scegliere $c_1 = 1$, dal momento che la retta avente come equazione la costante $1$ è un asintoto per la $\dfrac{f(n)}{g(n)}$ assegnata e per $c_2$ fissiamo un $n_0$, ad esempio assegniamo valore $1$, e ricaviamo $c_2 = \dfrac{f(n_0)}{g(n_0)} = \dfrac{f(1)}{g(1)} = 4$.\\

\begin{tcolorbox}[title=Attenzione]
	Negli esercizi si adotterà come convenzione che $\log(n) = \log_2(n)$ e non $\log_{10}(n) o \ln(n)$.
\end{tcolorbox}

\pagebreak
\paragraph*{Esercizio} Dimostrare che $3n\log(n) + \sqrt{n} =  \Theta(n\log(n))$
\paragraph*{Svolgimento} Iniziamo col verificare che esiste un asintoto orizzontale per il rapporto delle due funzioni:
$$\lim_{n \to \infty} \dfrac{3n\log(n)+ \sqrt{n}}{n\log(n)} = \lim_{n \to \infty} 3 + \cancelto{0}{\dfrac{1}{\sqrt{(n)}\log(n)}}=3$$
ed osserviamo che $3 + \dfrac{1}{\sqrt{(n)}\log(n)}$ è certamente una quantità positiva per $n>1$.\\\\
\begin{tcolorbox}[title=Alcune proprietà dei logaritmi]
	\label{tbox:logs}
	Ricorda che:
	\begin{itemize}
		\item $\log_{a} x < 0 \Leftrightarrow 0 < x < 1$.
		\item $\log_2(n) = \dfrac{\ln(n)}{\ln(2)}$
		\item $\log(a \cdot b) = \log(a) + \log(b)$
		\item $\log\left(\dfrac{a}{b}\right) = \log(a) - \log(b)$
	\end{itemize}
\end{tcolorbox}
Infine esaminiamo adesso la derivata del rapporto delle due funzioni:
$$\dfrac{\partial \left(3 + \dfrac{1}{\sqrt{(n)}\log(n)} \right)}{\partial n} =-\frac{1}{2n\sqrt{n}}\cdot\frac{1}{\log(n)} - \frac{1}{\sqrt{n}} \cdot \frac{1}{n(\log(n))^2\log{e}} $$
ed è evidente come la funzione è sempre negativa per qualsiasi $n > 1$, quindi il rapporto delle due funzioni ha una curva decrescente.
Infine, scegliamo un $n_0 = 2$ perché sappiamo che $n > 1$ e in modo che sia facile gestire la base $2$ del logaritmo. La costante $c_1 = 3$ per le medesime considerazioni fatte per l'esercizio precedente e $c_2 = \frac{f(n_0)}{g(n_0)} = 3 + \frac{1}{\sqrt{2}}$.
\paragraph*{Esercizio} Dimostrare che $f(n) = \Theta(g(n)) \Rightarrow \log(f(n)) = \Theta(g(n))$.
\paragraph*{Svolgimento} Dalla definizione di $\Theta(.)$ sappiamo che $$\exists n_0 > 0,\,\exists c_0,c_1 > 0,\,:\forall n \geq n_0,\,c_0 \cdot g(n) \leq f(n) \leq c_1 \cdot g(n)$$, quindi affinché quanto implicato nella proposizione sia vero, deve in particolare accadere che $\log(c_0 \cdot g(n)) \leq f(n) \leq \log(c_1 \cdot g(n))$. Per le proprietà dei logaritmi, riassunte nello specchietto \ref{tbox:logs}, possiamo riscrivere la relazione come $\log(c_0) +\log (g(n)) \leq f(n) \leq \log(c_1) + \log(g(n))$.\\
\begin{tcolorbox}[title=Ulteriori osservazioni]
	L'ultima relazione cui si è arrivati, posta in quella forma, non è sufficiente a provare quanto dobbiamo. Pertanto si rende necessario ricorrere ad un'ulteriore dimostrazione: data una costante arbitraria $k_1$, provare che $k_1+z(n)=\Theta(z(n))$.
	Ed infatti, assumendo $z(n)$ asintoticamente crescente, otteniamo:
	$$\lim_{n\to \infty} \frac{z(n)+k_1}{z(n)} = \lim_{n\to \infty} 1+ \cancelto{0}{\frac{k_1}{z(n)}} = 1$$ e quindi, ricordando quanto scritto in \ref{tbox:solving}, possiamo affermare che $$\exists p_1 > 0,p_2>0,\exists n_1 > 0\,:\forall n \geq n_1$$ e risulta che $$p_1\cdot z(n) \leq k_1+z(n) \leq p_2 \cdot z(n)$$ ed in particolare possiamo porre $z(n) = \log(n)$ dato che $z(n)$ l'abbiamo supposta come asintoticamente crescente.
\end{tcolorbox}
Per quanto osservato, grazie alla transitività, ponendo a sinistra $k = \log(c_0)$ e a destra $k = \log(c_1)$, sappiamo che $\exists p_1 > 0,p_2>0$ per i quali $p_1\cdot \log(g(n)) \leq \log(f(n)) \leq p_2 \cdot \log(g(n))$ e l'implicazione risulta adesso verificata.
\paragraph*{Esercizio} Dimostrare che $f(n) = \Theta(g(n)) \Rightarrow 2^{f(n)} = \Theta(2^{g(n)})$.
\paragraph*{Svolgimento} Per la definizione di $\Theta(.)$ che conosciamo, allora bisogna riuscire a dimostrare che $$\exists c_0 > 0,\,\exists c_1 > 0,\,\exists n_0 > 0:\forall n \geq n_0,\,c_0 \cdot g(n) \leq f(n) \leq c_1 \cdot g(n)$$ osserviamo che la funzione esponenziale è monotona, quindi per il problema in questione dobbiamo provare che $2^{c_0 \cdot g(n)} \leq 2^{f(n)} \leq 2^{c_1 \cdot g(n)}$ o, riscrivendo facendo uso delle proprietà degli esponenziali, equivalentemente $$\left(2^{g(n)}\right)^{c_0} \leq 2^{f(n)} \leq \left(2^{g(n)}\right)^{c_1}$$
a questo punto per riuscire a dimostrare con successo l'implicazione della proposizione, definita $z(n)$ come una qualsivoglia funzione crescente, dovremmo verificare che valga \linebreak $(z(n))^c = \Theta(z(n))\,\forall c > 0$ in modo da poterci infine ricondurre alla definizione di $\Theta(.)$ in maniera analoga a quanto esibito nello svolgimento dell'esercizio precedente.\\
\begin{tcolorbox}[title=Osservazione]
Si può osservare però che $(z(n))^c = \Theta(z(n))$ è valida solamente quando $c = 1$. Infatti sia $c > 1$ allora: $$\lim_{n \to \infty} \frac{(z(n))^c}{(z(n))} = \lim_{n \to \infty} (z(n))^{c-1} = \infty \neq k$$ e questo deve indurre a pensare che la proposizione sia \textbf{falsa} e dobbiamo produrre un controesempio.
\end{tcolorbox}
\subparagraph*{\fcolorbox{white}{gray}{\color{white}Controesempio}} Sulla base di quanto appena concluso, scelte opportunamente $f(n) = n$ e $g(n) = 2n$ per le quali è chiaro che sussista $f(n) = \Theta(g(n))$, ci chiediamo se basta questo a concludere che $2^n = \Theta(2^{2n})$. Facendo il limite, otteniamo che: $$\lim_{n \to \infty} \frac{2^{2n}}{2^n} = \lim_{n \to \infty} \frac{(2^n)^{\cancel{2}}}{\cancel{2^n}} = \lim_{n \to \infty} 2^n = \infty$$ quindi terminiamo la dimostrazione dichiarando falsa la proposizione.
\section{Valutare la complessità di un algoritmo}
\subsection{Il problema della massima somma di una sotto-sequenza}
\paragraph*{} Uno dei problemi notevoli che ci si appresta ad analizzare è quello del calcoli della massima somma all'interno di una arbitraria sotto-sequenza di numeri. In particolare questo algoritmo riceve in input la sequenza $A$ ed un intero $N > 1$, che ne rappresenta la lunghezza; in output restituisce un intero $S = \sum_{k = i}^{j} a_k$ dove $1 \leq i \leq j \leq N$ ed $S$ è il più grande possibile.

\subsubsection{Versione \#1}
\paragraph*{} Un approccio del tutto ingenuo al problema consiste nel generare tutte le possibili coppie di posizioni $(i, j)$ con $i \leq j$, valutare per ognuna di esse la somma, conservarne il valore se è più grande di quello trovato in precedenza.

\begin{lstlisting}[caption={Calcolo della massima somma di una sotto-sequenza, versione 1.},label={lst:max_seq_1}]
int MaxSeqSum(int N, A[])
	maxsum = 0
	FOR i = 1 TO N 
		FOR j = i TO N
			sum = 0
			FOR k = i TO j
				sum = sum + A[k]
				maxsum = max(maxsum, max)
	RETURN maxsum
\end{lstlisting}
Analizziamo adesso riga per riga la complessità dell'algoritmo.
\begin{table}[h]
	\centering
	\begin{tabular}{ c | c | c }
		\textbf{Linea} & \textbf{Num. op. elementari} & \textbf{Contributi} \\ \hline
		2 & $1$ & $1$ \\
		3 & $2$ & $N+1$ \\
		4 & $4$ & $\sum_{i = 1}^{N}(N-i+2)$ \\ 
		5 & $2$ & $\sum_{i = 1}^{N}(N-i+1)$ \\
		6 & $2$ & $\sum_{i=1}^{N}{\sum_{j=i}^{N} (j-i+2)}$ \\
		7 & $3$ & $\sum_{i=1}^{N}{\sum_{j=i}^{N} (j-i+1)}$ \\
		8 & $5$ & $\sum_{i=1}^{N}{\sum_{j=i}^{N} (j-i+1)}$ \\
		9 & $1$ & $1$ \\ 
	\end{tabular}
	\caption{Calcolo dei contributi per l'algoritmo mostrato nel listing \ref{lst:max_seq_1}.}
	\label{tbl:max_seq_1}
\end{table}
Dando una rapida occhiata alla complessità delle righe 7-8 mostrate in tabella \ref{tbl:max_seq_1}, che sono quelle più innestate all'interno dei cicli, nello sviluppare la sommatoria interna, ci accorgiamo del fatto che:
$$\sum_{j = i}^{N}(j-i+1) = \sum_{j = 1}^{N-i+1} j = \dfrac{(N-i+1)(N-i+2)}{2}$$ e pertanto
$$\sum_{i = 1}^{N} \dfrac{(N-i+1)(N-i+2)}{2} = O(n^3)\text{.}$$
\paragraph*{}Il cercare di risolvere il problema attraverso un approccio naïf e totalmente inclusivo di tutte le possibili sotto-sequenze, lo si paga con una complessità cubica.

\subsubsection{Versione \#2}
\paragraph*{}Ragionando sull'algoritmo possiamo introdurre un'ottimizzazione: si potrebbe evitare di ricalcolare da zero la somma di una sotto-sequenza $(i, j+1)$ quando l'algoritmo ha appena computato $(i, j)$.

\begin{lstlisting}[caption={Calcolo della massima somma di una sotto-sequenza, versione 2.},label={lst:max_seq_2}]
int MaxSeqSum(int N, A[])
	maxsum = 0
	FOR i = 1 TO N 
		sum = 0
		FOR j = i TO N
			sum = sum + A[j]
			maxsum = max(maxsum, max)
RETURN maxsum
\end{lstlisting}

\paragraph*{}Senza scendere nel dettaglio della complessità, possiamo notare come quei due cicli \texttt{FOR} innestati facciano sì che la funzione $T(n)$ associata a questo algoritmo sia $O(n^2)$.

\subsubsection{Versione \#3} Dal momento che non è possibile più introdurre significative ottimizzazioni sintattiche che snelliscano ulteriormente la ricerca limitandone la complessità, è necessario condurre un genere di ragionamento diverso, che consenta all'algoritmo di riconoscere ed evitare di computare a priori sotto-sequenze che certamente non possono restituire un valore che sia la massima somma. Proviamo a considerare la sotto-sequenza $(a_p, a_{r+k})$ qui di seguito schematizzata: 
\begin{figure}[hb]
	\centering
\begin{tikzpicture}[array/.style={rectangle split,rectangle split horizontal, rectangle split parts=#1,draw, anchor=center, fill=white}]
\node[array=14] (a) {
	\nodepart{one}
	\nodepart{two}$\cdots$
	\nodepart{three}$a_p$
	\nodepart{four}
	\nodepart{five}
	\nodepart{six}$a_{r-1}$
	\nodepart{seven}$a_r$
	\nodepart{eight}$a_{r+1}$
	\nodepart{nine}
	\nodepart{ten}
	\nodepart{eleven}
	\nodepart{twelve}$a_{r+k}$
	\nodepart{thirteen}
	\nodepart{fourteen}$\cdots$
};
\end{tikzpicture}
	\label{fig:arrmaxsum}
	\caption{Schematizzazione di una qualsiasi sotto-sequenza.}
\end{figure}

matematicamente valgono le due seguenti:
\begin{enumerate}
	\item $a_p + \cdots + a_r \geq 0 \Rightarrow a_p + \cdots + a_{r+k} \geq a_{r+1} + \cdots + a_{r+k},\,\forall k \geq 1$ 
	\item $a_p + \cdots + a_{r-1} > 0 \wedge a_p + \cdots + a_r < 0 \Rightarrow a_p + \cdots + a_{r+k} \leq a_{r+1} + \cdots + a_{r+k},\, \forall k \geq 1\text{.}$
\end{enumerate}
In soldoni le due proprietà enunciano che, finché la somma di tutti gli elementi che vanno da $a_p$ ad $a_r$ è positiva, allora effettivamente la somma che va da $a_p$ ad $a_{r+k}$ è maggiore della somma da $a_p$ ad $a_r$. Viceversa se l'elemento $r$-esimo rende il contributo della sotto-sequenza $a_p$ ad $a_r$ negativo, allora la somma da $a_{r+1}$ ad $a_{r+k}$ è certamente maggiore della somma da $a_p$ ad $a_r$.\\\\Quindi, sulla base di queste affermazioni, è possibile scrivere una nuova versione dell'algoritmo, presupponendo che alla fine sia interessante conoscere anche quale è l'effettiva sotto-sequenza che genera la massima somma:

\begin{lstlisting}[caption={Calcolo della massima somma di una sotto-sequenza, versione 3.},label={lst:max_seq_3}]
int MaxSeqSum(int N, A[])
	maxsum = 0
	sum = 0
	i = 1
	FOR j = i TO N
		IF (sum + A[j] > 0) THEN
			sum = sum + A[j]
		ELSE
			sum = 0
			i = j+1
		IF (maxsum < sum) THEN
			maxsum = sum
			max_start = i
			max_end = j
\end{lstlisting}

\begin{table}[h]
	\centering
	\begin{tabular}{ c | c | c }
		\textbf{Linee} & \textbf{Num. op. elementari} & \textbf{Contributi} \\ \hline
		2 & $1$ & $1$ \\
		3 & $2$ & $1$ \\
		4 & $1$ & $1$ \\ 
		5 & $3$ & $N+1$ \\
		6-10 & $2$ & $N$ \\
		11-14 & $3$ & tra $1$ e $N$ \\
	\end{tabular}
	\caption{Calcolo dei contributi per l'algoritmo mostrato nel listing \ref{lst:max_seq_3}.}
	\label{tbl:max_seq_3}
\end{table}

I rami della struttura \texttt{IF-ELSE} delle linee 6-10 sono eseguite in tutto $N$ volte, in quanto l'algoritmo, ad ogni iterazione effettuata, o prenderà un blocco o un altro. L'ultimo \texttt{IF} dell'algoritmo invece è impredicibile a priori, ma certamente sarà eseguito almeno $1$ volta oppure ogni volta, cioè $N$.

È possibile constatare come questo algoritmo lavori in maniera lineare rispetto alla dimensione dell'input.

\subsection{La complessità di Insertion Sort}
In questa sezione diamo un'occhiata più da vicino ad uno degli algoritmi che risolvono correttamente il problema dell'ordinamento. Insertion Sort è uno di quegli algoritmi di ordinamento che ogni giocatore applica inconsapevolmente quando gli viene dato un mazzo di carte.
\pagebreak
\begin{lstlisting}[caption={Insertion Sort},label={lst:insert_sort}]
InsertionSort(A[])
	FOR j = 2 TO length(A)
		key = A[j]
		i = j - 1
		WHILE (i > 0) AND (a[i] > key) DO
			A[i+1] = A[i]
			i = i - 1
		A[i+1] = key
\end{lstlisting}

\begin{table}[hb]
	\centering
	\begin{tabular}{ c | c | c }
		\textbf{Linea} & \textbf{Num. op. elementari} & \textbf{Contributi} \\ 
		2 & $c_1$ & $n$ \\
		3 & $c_2$ & $n-1$ \\
		4 & $c_3$ & $n-1$ \\ 
		5 & $c_4$ & $\sum_{j=2}^{n}t_j$ \\
		6 & $c_5$ & $\sum_{j=2}^{n}(t_j-1)$ \\
		7 & $c_6$ & $\sum_{j=2}^{n}(t_j-1)$ \\
		8 & $c_7$ & $n-1$ \\ 
	\end{tabular}
	\caption{Calcolo dei contributi per l'algoritmo mostrato nel listing \ref{lst:insert_sort}}
	\label{tbl:insert_sort}
\end{table}

\paragraph*{}La complessità calcolata per l'algoritmo \ref{lst:insert_sort} è:
$T(n) = c_1 \cdot n + c_2 \cdot (n-1) + c_3 \cdot (n-1) + c_4 \cdot \sum_{j=2}^{n}t_j + c_5 \cdot \sum_{j=2}^{n}(t_j-1) + c_6 \cdot \sum_{j=2}^{n}(t_j-1) +  c_7 \cdot (n-1)$.\\
\begin{tcolorbox}[title=Per fare chiarezza]
	Diversamente da quanto accade per il costrutto \texttt{FOR}, generalmente il numero di iterazioni compiute dall'istruzione \texttt{WHILE} non è predeterminato ed inoltre, in questo caso particolare, il secondo è incluso nel primo.\\Per questo motivo per rappresentare l'espressione che quantifichi il numero di esecuzioni, è necessario adoperare una notazione che rifletta la natura di ambo i cicli.\\
	Siano $t_2$, $t_3$, $\dots$, $t_n$ il numero di esecuzioni di una riga rispettivamente per $j=2$, $j=3$, $\dots$, $j=n$, allora si scrive $$\sum_{j=2}^{n} t_j$$ laddove i termini $n$ e $j=2$ della sommatoria riflettono i limiti del ciclo \texttt{FOR} esterno e $t_j$ è il numero di esecuzioni determinato dal \texttt{WHILE} per un fissato valore di $j$.
\end{tcolorbox}
\paragraph*{}L'espressione $T(n)$ rappresenterebbe il valore dell'analisi se per ogni $j$, conoscessimo il rispettivo valore $t_j$, ma questa funzione non dipende esclusivamente da $n$, come possiamo fare a trovare una forma chiusa?
\paragraph*{}Benché le istanze che possono presentarsi siano infinite e quindi troppe per poterle analizzare una ad una, possiamo farle ricadere in tre grandi famiglie e quindi essere sequenze da
\begin{description}
	\item [caso migliore] istanze che minimizzino il lavoro dell'algoritmo
	\item [caso peggiore] istanze che massimizzino il lavoro dell'algoritmo
	\item [caso medio] istanze rimanenti
\end{description}

\subsubsection{Caso migliore} 
\paragraph*{}Per l'algoritmo in questione, il caso migliore che si possa presentare è quello per cui ogni elemento della sequenza è già posto in ordine crescente. Di conseguenza l'istruzione \texttt{WHILE} farà solo un'esecuzione per il controllo della sua condizione che risulta sempre falsa. Quindi risulta $\bm{t_j = 1},\,\forall j=2,\dots, n$, da cui:

\begin{dmath*}
	T(n) = c_1 \cdot n + c_2 \cdot (n-1) + c_3 \cdot (n-1) + c_4 \cdot \sum_{j=2}^{n}t_j + c_5 \cdot \sum_{j=2}^{n}(t_j-1) + c_6 \cdot \sum_{j=2}^{n}(t_j-1) +  c_7 \cdot (n-1)
	= c_1 \cdot n + c_2 \cdot (n-1) + c_3 \cdot (n-1) + c_4 \cdot (n-1) + c_5 \cdot \cancel{\sum_{j=2}^{n}(1-1)} + c_6 \cdot \cancel{\sum_{j=2}^{n}(1-1)} +  c_7 \cdot (n-1)
	= c_1\cdot n + c_2 \cdot (n-1) + c_3 \cdot (n-1) + c_4 \cdot (n-1) + c_7 \cdot (n-1)
	= n \cdot (c_1+c_2+c_3+c_4+c_7) - (c_2+c_3+c_4+c_7)
	= a\cdot n + b = \Theta(n).
\end{dmath*}

\begin{tcolorbox}[title=Ricordando che...]
	Prima di affrontare i calcoli per la valutazione del caso peggiore, teniamo ben a mente le seguenti:
	\begin{itemize}
		\item $\sum_{\bm{i=2}}^{n}i=\sum_{\bm{i=1}}^{n}(i)-1=\dfrac{1}{2}n(n+1)-1$
		\item $\sum_{\bm{i=2}}^n(i-1) =\sum_{\bm{i=2}}^{n}i - \sum_{\bm{i=2}}^{n}1=\dfrac{1}{2}n(n-1)$
	\end{itemize}
\end{tcolorbox}

\subsubsection{Caso peggiore}
\paragraph*{}Per l'algoritmo il caso peggiore è rappresentato da quell'istanze che hanno tutti gli elementi posizionati in ordine decrescente. Ad ogni ciclo, il valore di $j$ è sempre massimizzato, quindi $\bm{t_j = j},\,\forall j=2,\dots, n$, pertanto:
\begin{dmath*}
	T(n) = c_1 \cdot n + c_2 \cdot (n-1) + c_3 \cdot (n-1) + c_4 \cdot \sum_{j=2}^{n}t_j + c_5 \cdot \sum_{j=2}^{n}(t_j-1) + c_6 \cdot \sum_{j=2}^{n}(t_j-1) +  c_7 \cdot (n-1)
	= c_1 \cdot n + c_2 \cdot (n-1) + c_3 \cdot (n-1) + c_4 \cdot \sum_{j=2}^{n}j + c_5 \cdot \sum_{j=2}^{n}(j-1) + c_6 \cdot \sum_{j=2}^{n}(j-1) +  c_7 \cdot (n-1)
	= c_1 \cdot n + c_2 \cdot (n-1) + c_3 \cdot (n-1) + c_4 \cdot \left[\dfrac{1}{2}n^2+\dfrac{1}{2}n-1\right] + (c_5+c_6) \cdot \left[\dfrac{1}{2}n^2+\dfrac{1}{2}n\right]+c_7(n-1)
	= \dfrac{1}{2}n^2(c_4+c_5+c_6)+\dfrac{1}{2}n\cdot(2c_1+2c_2+2c_3+c_4-c_5-c_6)-(c_2+c_3+c_4+c_7)
	= a^2n+bn+c = \Theta(n^2)
\end{dmath*}

\begin{tcolorbox}[title=Ricordando che...]
	Sia $k$ una costante moltiplicativa, una delle proprietà della sommatoria consente questa uguaglianza:
	$$\sum_{\bm{i=0}}^{n}k\cdot i=k\cdot \left[\sum_{\bm{i=0}}^{n}i\right]$$
\end{tcolorbox}

\subsubsection{Caso medio} L'analisi del caso migliore e del caso peggiore determinano dei risultati tra loro decisamente discordanti e quindi non conclusivi. Infatti sia $T(n)$ il tempo associato a questo algoritmo, allora $T(n)$ si trova compreso tra la funzione $f(n) = n$ e $g(n) = n^2$ ed esistono infinite funzioni tra queste due, quindi bisogna stabilire a quale di esse il tempo del caso medio si avvicina.\\\\L'idea di calcolare una media, naturalmente, consisterebbe di fatto nel sommare tutte le funzioni che ottengo per ciascuna istanza possibile di lunghezza $N$ e dividerlo per il numero delle istanze. Ma notiamo che è un'operazione impraticabile essendo infinite le possibili istanze. Tuttavia possiamo osservare che in realtà non è vero che due istanze della medesima lunghezza e contenenti valori diversi determinino tempi diversi. Infatti se prendiamo le seguenti due sequenze di lunghezza 5: \texttt{A1 = [1,2,3,4,5]} e \texttt{A2 = [22,33,44,55,66]}, possiamo certamente affermare che esse hanno uguale complessità e quindi, dal punto di vista dell'algoritmo, richiedono lo stesso costo computazionale.\\\\Supponiamo di voler raggruppare tutte le istanze con il medesimo costo computazionale all'interno di una classe di equivalenza, ci accorgiamo che, in particolare, ognuna di queste partizioni ha una cardinalità infinita poiché infinite sono le sequenze ordinate in maniera crescente, infinite sono le sequenze ordinate in maniera decrescente e così via. Ci chiediamo quante sono queste classi di equivalenza. Dal momento che, a prescindere dai valori specifici di ogni sequenza, proprio come esemplificato in figura \ref{fig:partizcompl}, è la posizione degli elementi a determinare il costo computazionale richiesto dall'algoritmo per riordinare i valori contenuti, ne consegue che le classi di equivalenza sono tante quante sono le possibili permutazioni su una sequenza di $N$ elementi, vale a dire $n!$. Adesso la media potrebbe essere calcolata, ma ci accontentiamo di qualcosa di più semplice.

\begin{figure}[hb]
	\centering
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\begin{tikzpicture}[array/.style={rectangle split,rectangle split horizontal, rectangle split parts=#1,draw, anchor=center, fill=white}]
		\node[array=5] (a) {
			\nodepart{one}$1$
			\nodepart{two}$2$
			\nodepart{three}$3$
			\nodepart{four}$4$
			\nodepart{five}$5$
		};
		\end{tikzpicture}
		\caption{L'algoritmo di Insertion sort impiega un tempo lineare per riordinare questa sequenza.}
		\label{fig:partizcompl1}	
	\end{subfigure}
	\qquad
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\begin{tikzpicture}[array/.style={rectangle split,rectangle split horizontal, rectangle split parts=#1,draw, anchor=center, fill=white}]
		\node[array=5] (a) {
			\nodepart{one}$5$
			\nodepart{two}$4$
			\nodepart{three}$3$
			\nodepart{four}$2$
			\nodepart{five}$1$
		};
		\end{tikzpicture}
		\caption{L'algoritmo di Insertion sort impiega un tempo quadratico per riordinare questa sequenza.}
		\label{fig:partizcompl2}
	\end{subfigure}
	\caption{Le due sequenze, pur contenendo i medesimi valori, hanno costo computazione diverso che dipende dalla specifica permutazione.} 
	\label{fig:partizcompl}
\end{figure}
\pagebreak
\paragraph{Caso medio semplificato}Il caso medio è rappresentato dall'insieme di istanze per le quali solo la metà degli elementi risulta essere già ordinato e dunque in media ad ogni iterazione del ciclo \texttt{WHILE} controlliamo solamente metà del sotto-array.\\\\Pertanto $\bm{t_j = \frac{j}{2}},\,\forall j=2,\dots, n$ e quindi:

\begin{dmath*}
	T(n) = c_1 \cdot n + c_2 \cdot (n-1) + c_3 \cdot (n-1) + c_4 \cdot \sum_{j=2}^{n}t_j + c_5 \cdot \sum_{j=2}^{n}(t_j-1) + c_6 \cdot \sum_{j=2}^{n}(t_j-1) +  c_7 \cdot (n-1)
	= c_1 \cdot n + c_2 \cdot (n-1) + c_3 \cdot (n-1) + c_4 \cdot \sum_{j=2}^{n}\dfrac{j}{2} + c_5 \cdot \sum_{j=2}^{n}{\left(\dfrac{j}{2}-1\right)}+c_6 \cdot \sum_{j=2}^{n}{\left(\dfrac{j}{2}-1\right)}+ c_7 \cdot (n-1)
	= c_1 \cdot n + c_2 \cdot (n-1) + c_3 \cdot (n-1) + \dfrac{c_4}{2} \sum_{j=2}^{n}{j} + (c_5+c_6) \cdot \left(\frac{1}{2}\sum_{j=2}^{n}{j} - \sum_{j=2}^{n}{1}\right)+  c_7 \cdot (n-1)
	= c_1 \cdot n + c_2 \cdot (n-1) + c_3 \cdot (n-1) + c_4 \cdot \dfrac{n(n+1-2)}{4} + (c_5+c_6) \cdot \dfrac{n^2-3n+2}{4} +  c_7 \cdot (n-1)
	= {n^2\cdot \left(\dfrac{c_4+c_5+c_6}{4}\right) + n\cdot \left[\dfrac{4\cdot (c_1+c_2+c_3-c_7) + c_4- 3(c_5+c_6)}{4}\right]-\left(\dfrac{2\cdot (c_2+c_3+c_7)-(c_4+c_5+c_6)}{2}\right)}
	= an^2+bn+c = \Theta(n^2)
\end{dmath*}
\end{document}
